#!/usr/bin/env bash
###############################################################################
# This script follows the principles outlined here (see for details):
# Bash Boilerplate: https://github.com/xwmx/bash-boilerplate/blob/master/bash-subcommands
#
#
# cephtools
#
#
# Developed by Todd Knutson <knut0297@umn.edu>, Minnesota Supercomputing Institute.
#
#
#
#
###############################################################################






###############################################################################
# Strict Mode
###############################################################################

# Treat unset variables and parameters other than the special parameters â€˜@â€™ or
# â€˜*â€™ as an error when performing parameter expansion. 
set -o nounset

# Exit immediately if a pipeline returns non-zero.
#
# NOTE: This can cause unexpected behavior. When using `read -rd ''` with a
# heredoc, the exit status is non-zero, even though there isn't an error.
set -o errexit

# Print a helpful message if a pipeline with non-zero exit code causes the
# script to exit as described above.
trap 'echo "Aborting due to errexit on line $LINENO. Exit code: $?" >&2' ERR

# Allow the above trap be inherited by all functions in the script.
set -o errtrace

# Return value of a pipeline is the value of the last (rightmost) command to
# exit with a non-zero status, or zero if all commands in the pipeline exit
# successfully.
set -o pipefail

# Set $IFS to only newline and tab.
IFS=$'\n\t'

###############################################################################
# Globals ###############################################################################


# This program's basename.
_ME="$(basename "${0}")"




# Manually set this to to current version of the program. Adhere to the
# semantic versioning specification: http://semver.org
#
# MAJOR version when you make incompatible API changes,
# MINOR version when you add functionality in a backwards compatible manner, and
# PATCH version when you make backwards compatible bug fixes.
_VERSION="0.1.0"



# The subcommand to be run by default, when no subcommand name is specified.
DEFAULT_SUBCOMMAND="${DEFAULT_SUBCOMMAND:-help}"

###############################################################################
# Debug
###############################################################################

# _debug()
#
# Usage:
#   _debug <command> <options>...
#
# Description:
#   Execute a command and print to standard error. The command is expected to
#   print a message and should typically be either `echo`, `printf`, or `cat`.
#
# Example:
#   _debug printf "Debug info. Variable: %s\\n" "$0"
__DEBUG_COUNTER=0
_debug() {
  if ((${_USE_DEBUG:-0}))
  then
    __DEBUG_COUNTER=$((__DEBUG_COUNTER+1))
    {
      # Prefix debug message with "bug (U+1F41B)"
      printf "ðŸ›  %s " "${__DEBUG_COUNTER}"
      "${@}"
      printf "â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•\\n"
    } 1>&2
  fi
}

###############################################################################
# Error Messages
###############################################################################

# _exit_1()
#
# Usage:
#   _exit_1 <command>
#
# Description:
#   Exit with status 1 after executing the specified command with output
#   redirected to standard error. The command is expected to print a message
#   and should typically be either `echo`, `printf`, or `cat`.
_exit_1() {
  {
    printf "%s " "$(tput setaf 1)!$(tput sgr0)"
    "${@}"
  } 1>&2
  exit 1
}

# _warn()
#
# Usage:
#   _warn <command>
#
# Description:
#   Print the specified command with output redirected to standard error.
#   The command is expected to print a message and should typically be either
#   `echo`, `printf`, or `cat`.
_warn() {
  {
    printf "%s " "$(tput setaf 1)!$(tput sgr0)"
    "${@}"
  } 1>&2
}

###############################################################################
# Utility Functions
###############################################################################

# _function_exists()
#
# Usage:
#   _function_exists <name>
#
# Exit / Error Status:
#   0 (success, true) If function with <name> is defined in the current
#                     environment.
#   1 (error,  false) If not.
#
# Other implementations, some with better performance:
# http://stackoverflow.com/q/85880
_function_exists() {
  [ "$(type -t "${1}")" == 'function' ]
}

# _command_exists()
#
# Usage:
#   _command_exists <name>
#
# Exit / Error Status:
#   0 (success, true) If a command with <name> is defined in the current
#                     environment.
#   1 (error,  false) If not.
#
# Information on why `hash` is used here:
# http://stackoverflow.com/a/677212
_command_exists() {
  hash "${1}" 2>/dev/null
}

# _contains()
#
# Usage:
#   _contains <query> <list-item>...
#
# Exit / Error Status:
#   0 (success, true)  If the item is included in the list.
#   1 (error,  false)  If not.
#
# Examples:
#   _contains "${_query}" "${_list[@]}"
_contains() {
  local _query="${1:-}"
  shift

  if [[ -z "${_query}"  ]] ||
     [[ -z "${*:-}"     ]]
  then
    return 1
  fi

  for __element in "${@}"
  do
    [[ "${__element}" == "${_query}" ]] && return 0
  done

  return 1
}

# _join()
#
# Usage:
#   _join <delimiter> <list-item>...
#
# Description:
#   Print a string containing all <list-item> arguments separated by
#   <delimeter>.
#
# Example:
#   _join "${_delimeter}" "${_list[@]}"
#
# More information:
#   https://stackoverflow.com/a/17841619
_join() {
  local _delimiter="${1}"
  shift
  printf "%s" "${1}"
  shift
  printf "%s" "${@/#/${_delimiter}}" | tr -d '[:space:]'
}

# _blank()
#
# Usage:
#   _blank <argument>
#
# Exit / Error Status:
#   0 (success, true)  If <argument> is not present or null.
#   1 (error,  false)  If <argument> is present and not null.
_blank() {
  [[ -z "${1:-}" ]]
}

# _present()
#
# Usage:
#   _present <argument>
#
# Exit / Error Status:
#   0 (success, true)  If <argument> is present and not null.
#   1 (error,  false)  If <argument> is not present or null.
_present() {
  [[ -n "${1:-}" ]]
}

# _interactive_input()
#
# Usage:
#   _interactive_input
#
# Exit / Error Status:
#   0 (success, true)  If the current input is interactive (eg, a shell).
#   1 (error,  false)  If the current input is stdin / piped input.
_interactive_input() {
  [[ -t 0 ]]
}

# _piped_input()
#
# Usage:
#   _piped_input
#
# Exit / Error Status:
#   0 (success, true)  If the current input is stdin / piped input.
#   1 (error,  false)  If the current input is interactive (eg, a shell).
_piped_input() {
  ! _interactive_input
}

###############################################################################
# describe
###############################################################################

# describe()
#
# Usage:
#   describe <name> <description>
#   describe --get <name>
#
# Options:
#   --get  Print the description for <name> if one has been set.
#
# Examples:
# ```
#   describe "list" <<HEREDOC
# Usage:
#   ${_ME} list
#
# Description:
#   List items.
# HEREDOC
#
# describe --get "list"
# ```
#
# Set or print a description for a specified subcommand or function <name>. The
# <description> text can be passed as the second argument or as standard input.
#
# To make the <description> text available to other functions, `describe()`
# assigns the text to a variable with the format `$___describe_<name>`.
#
# When the `--get` option is used, the description for <name> is printed, if
# one has been set.
#
# NOTE:
#
# The `read` form of assignment is used for a balance of ease of
# implementation and simplicity. There is an alternative assignment form
# that could be used here:
#
# var="$(cat <<'HEREDOC'
# some message
# HEREDOC
# )
#
# However, this form appears to require trailing space after backslases to
# preserve newlines, which is unexpected. Using `read` simply requires
# escaping backslashes, which is more common.
describe() {
  _debug printf "describe() \${*}: %s\\n" "$@"
  [[ -z "${1:-}" ]] && _exit_1 printf "describe(): <name> required.\\n"

  if [[ "${1}" == "--get" ]]
  then # get ------------------------------------------------------------------
    [[ -z "${2:-}" ]] &&
      _exit_1 printf "describe(): <description> required.\\n"

    local _name="${2:-}"
    local _describe_var="___describe_${_name}"

    if [[ -n "${!_describe_var:-}" ]]
    then
      printf "%s\\n" "${!_describe_var}"
    else
      printf "No additional information for \`%s\`\\n" "${_name}"
    fi
  else # set ------------------------------------------------------------------
    if [[ -n "${2:-}" ]]
    then # argument is present
      read -r -d '' "___describe_${1}" <<HEREDOC
${2}
HEREDOC
    else # no argument is present, so assume piped input
      # `read` exits with non-zero status when a delimeter is not found, so
      # avoid errors by ending statement with `|| true`.
      read -r -d '' "___describe_${1}" || true
    fi
  fi
}

###############################################################################
# Program Option Parsing
#
# NOTE: The `getops` builtin command only parses short options and BSD `getopt`
# does not support long arguments (GNU `getopt` does), so use custom option
# normalization and parsing.
#
# For a pure bash `getopt` function, try pure-getopt:
#   https://github.com/agriffis/pure-getopt
#
# More info:
#   http://wiki.bash-hackers.org/scripting/posparams
#   http://www.gnu.org/software/libc/manual/html_node/Argument-Syntax.html
#   http://stackoverflow.com/a/14203146
#   http://stackoverflow.com/a/7948533
#   https://stackoverflow.com/a/12026302
#   https://stackoverflow.com/a/402410
###############################################################################

# Normalize Options ###########################################################

# Source:
#   https://github.com/e36freak/templates/blob/master/options

# Iterate over options, breaking -ab into -a -b and --foo=bar into --foo bar
# also turns -- into --endopts to avoid issues with things like '-o-', the '-'
# should not indicate the end of options, but be an invalid option (or the
# argument to the option, such as wget -qO-)
unset options
# while the number of arguments is greater than 0
while ((${#}))
do
  case "${1}" in
    # if option is of type -ab
    -[!-]?*)
      # loop over each character starting with the second
      for ((i=1; i<${#1}; i++))
      do
        # extract 1 character from position 'i'
        c="${1:i:1}"
        # add current char to options
        options+=("-${c}")
      done
      ;;
    # if option is of type --foo=bar, split on first '='
    --?*=*)
      options+=("${1%%=*}" "${1#*=}")
      ;;
    # end of options, stop breaking them up
    --)
      options+=(--endopts)
      shift
      options+=("${@}")
      break
      ;;
    # otherwise, nothing special
    *)
      options+=("${1}")
      ;;
  esac

  shift
done
# set new positional parameters to altered options. Set default to blank.
set -- "${options[@]:-}"
unset options

# Parse Options ###############################################################

_SUBCOMMAND=""
_SUBCOMMAND_ARGUMENTS=()
_USE_DEBUG=0

while ((${#}))
do
  __opt="${1}"

  shift

  case "${__opt}" in
    -h|--help)
      _SUBCOMMAND="help"
      ;;
    --version)
      _SUBCOMMAND="version"
      ;;
    --debug)
      _USE_DEBUG=1
      ;;
    *)
      # The first non-option argument is assumed to be the subcommand name.
      # All subsequent arguments are added to $_SUBCOMMAND_ARGUMENTS.
      if [[ -n "${_SUBCOMMAND}" ]]
      then
        _SUBCOMMAND_ARGUMENTS+=("${__opt}")
      else
        _SUBCOMMAND="${__opt}"
      fi
      ;;
  esac
done

###############################################################################
# Main
###############################################################################

# Declare the $_DEFINED_SUBCOMMANDS array.
_DEFINED_SUBCOMMANDS=()

# _main()
#
# Usage:
#   _main
#
# Description:
#   The primary function for starting the program.
#
#   NOTE: must be called at end of program after all subcommands are defined.
_main() {
  # If $_SUBCOMMAND is blank, then set to `$DEFAULT_SUBCOMMAND`
  if [[ -z "${_SUBCOMMAND}" ]]
  then
    _SUBCOMMAND="${DEFAULT_SUBCOMMAND}"
  fi

  for __name in $(declare -F | grep -v "declare -fx")
  do
    # Each element has the format `declare -f function_name`, so set the name
    # to only the 'function_name' part of the string.
    local _function_name
    _function_name=$(printf "%s" "${__name}" | awk '{ print $3 }')

    if ! { [[ -z "${_function_name:-}"                      ]] ||
           [[ "${_function_name}" =~ ^_(.*)                 ]] ||
           [[ "${_function_name}" == "bats_readlinkf"       ]] ||
           [[ "${_function_name}" == "describe"             ]] ||
           [[ "${_function_name}" == "shell_session_update" ]]
    }
    then
      _DEFINED_SUBCOMMANDS+=("${_function_name}")
    fi
  done

  # If the subcommand is defined, run it, otherwise return an error.
  if _contains "${_SUBCOMMAND}" "${_DEFINED_SUBCOMMANDS[@]:-}"
  then
    # Pass all comment arguments to the program except for the first ($0).
    ${_SUBCOMMAND} "${_SUBCOMMAND_ARGUMENTS[@]:-}"
  else
    _exit_1 printf "Unknown subcommand: %s\\n" "${_SUBCOMMAND}"
  fi
}


###############################################################################
# Default Subcommands
###############################################################################

# help ########################################################################

describe "help" <<HEREDOC
Usage:
  ${_ME} help [<subcommand>]

Description:
  Display help information for ${_ME} or a specified subcommand.
HEREDOC
help() {
  if [[ "${1:-}" ]]
  then
    describe --get "${1}"
  else
    cat <<HEREDOC
cephtools

Tools for transfering data between panfs (tier1) and ceph (tier2) MSI storage.

Version: ${_VERSION}

Usage:
  ${_ME} <subcommand> [--subcommand-options] [<arguments>]
  ${_ME} -h | --help
  ${_ME} --version

Options:
  -h --help  Display this help information.
  --version  Display version information.

Help:
  ${_ME} help [<subcommand>]

$(subcommands --)
HEREDOC
  fi
}

# subcommands #################################################################

describe "subcommands" <<HEREDOC
Usage:
  ${_ME} subcommands [--raw]

Options:
  --raw  Display the subcommand list without formatting.

Description:
  Display the list of available subcommands.
HEREDOC
subcommands() {
  if [[ "${1:-}" == "--raw" ]]
  then
    printf "%s\\n" "${_DEFINED_SUBCOMMANDS[@]}"
  else
    printf "Available subcommands:\\n"
    printf "  %s\\n" "${_DEFINED_SUBCOMMANDS[@]}"
  fi
}

# version #####################################################################

describe "version" <<HEREDOC
Usage:
  ${_ME} ( version | --version )

Description:
  Display the current program version.

  To save you the trouble, the current version is ${_VERSION}
HEREDOC
version() {
  printf "%s\\n" "${_VERSION}"
}





# ---------------------------------------------------------------------
# panfs2ceph
# ---------------------------------------------------------------------

describe "panfs2ceph" <<HEREDOC
---------------------------------------------------------------------
Usage:
    ${_ME} panfs2ceph [options] --remote <REMOTE> --bucket <BUCKET> --path <DIR_PATH>

Options:
    -r|--remote <STRING>    Rclone remote name. (use "rclone listremotes" for available
                            remotes). Rclone remotes must be set up using "rclone init"
                            and can be viewed at: ~/.config/rclone/rclone.config.
                            
    -b|--bucket <STRING>    Name of the ceph bucket that data should be used for the 
                            transfer.
    
    -p|--path <STRING>      Absolute or relative path to the directory that should be 
                            transfered.
    
    -d|--dry_run            Dry run option will be applied to rclone commands. Nothing 
                            transfered or deleted when scripts run.
    
    -v|--verbose            Verbose mode will be applied to rclone commands.
    
    -e|--delete_empty_dirs  Do NOT transfer empty dirs on panfs to ceph. [Default is to 
                            create a hidden file (".empty_dir") inside all empty dirs so 
                            they get transfered to ceph. Setting this flag will not create
                            the ".empty_dir" files, thus empty dirs will not get copied to
                            ceph.
                            
    -t|--threads <INT>      Threads to use for uploading with rclone. [Default = 1].
    
    --debug                 Print additional info when running this command (like verbose 
                            mode). 

Description:
  Archiving tool to copy a single directory from tier 1 (panfs) storage to tier 2 (ceph).
  
Help (print this screen):
    ${_ME} help panfs2ceph

Version: ${_VERSION}
Questions: Todd Knutson (knut0297@umn.edu)
GitHub: https://github.umn.edu/knut0297org/cephtools
---------------------------------------------------------------------
HEREDOC

panfs2ceph() {
#     echo ALL ARGS:
#     echo "${@:-}"
#     echo "${#}"


    
    # Parse Options ###############################################################

    # Initialize program option variables.
    local _USE_DEBUG=0
    local _bucket=
    local _remote=
    local _path=
    local _dry_run=
    local _verbose=
    local _delete_empty_dirs=0
    local _threads="1"

    # __get_option_value()
    #
    # Usage:
    #   __get_option_value <option> <value>
    #
    # Description:
    #  Given a flag (e.g., -e | --example) return the value or exit 1 if value
    #  is blank or appears to be another option.
    __get_option_value() {
      local __arg="${1:-}"
      local __val="${2:-}"
      
      if [[ -n "${__val:-}" ]] && [[ ! "${__val:-}" =~ ^- ]]
      then
        printf "%s\\n" "${__val}"
      else
        _exit_1 printf "%s requires a valid argument.\\n" "${__arg}"
      fi
    }


    # For flags (i.e. no corresponding value), do not shift inside the case testing
    # statement. For options with required value, shift inside case testing statement, 
    # so the loop moves twice. 
    while ((${#}))
    do
        __arg="${1:-}"
        __val="${2:-}"

        case "${__arg}" in
        --debug)
            _USE_DEBUG=1
            ;;
        -d|--dry_run)
            _dry_run="--dry-run"
            ;;
        -v|--verbose)
            _verbose="-v"
            ;;
        -e|--delete_empty_dirs)
            _delete_empty_dirs=1
            ;;
        -b|--bucket)
            _bucket="$(__get_option_value "${__arg}" "${__val:-}")"
            shift
            ;;
        -r|--remote)
            _remote="$(__get_option_value "${__arg}" "${__val:-}")"
            shift
            ;;
        -p|--path)
            _path="$(__get_option_value "${__arg}" "${__val:-}")"
            shift
            ;;
        -t|--threads)
            _threads="$(__get_option_value "${__arg}" "${__val:-}")"
            shift
            ;;
        --endopts)
            # Terminate option parsing.
            break
            ;;
        -*)
            _exit_1 printf "Unexpected option: %s\\n" "${__arg}"
            ;;
        *)
            describe --get panfs2ceph
            _exit_1 printf "Unexpected positional arg: %s\\n" "${__arg}"
            ;;
        esac

        shift
    done


    # ---------------------------------------------------------------------
    # Check and print input options
    # ---------------------------------------------------------------------

    printf -- "Program options used:\\n"
    printf -- "--debug: %s\\n" "$_USE_DEBUG"
    printf -- "--bucket: %s\\n" "$_bucket"
    printf -- "--remote: %s\\n" "$_remote"
    printf -- "--path: %s\\n" "$_path"
    printf -- "--dry_run: %s\\n" "$_dry_run"
    printf -- "--verbose: %s\\n" "$_verbose"
    printf -- "--delete_empty_dirs: %s\\n" "$_delete_empty_dirs"
    printf -- "--threads: %s\\n" "$_threads"


    # If required options are empty or null, exit.
    if [ -z "${_remote}" ]
    then
        _exit_1 printf "The '--remote' option must be specified and not be empty or null."
    fi
    if [ -z "${_bucket}" ]
    then
        _exit_1 printf "The '--bucket' option must be specified and not be empty or null."
    fi
    if [ -z "${_path}" ]
    then
        _exit_1 printf "The '--path' option must be specified and not be empty or null."
    fi
    

    _root_path_dir=$(readlink -m "${_path}")
    if [ ! -d "${_root_path_dir}" ]
    then
        _exit_1 printf "The '--path' option specified is not a valid directory. \\nReadlink does not convert to a valid directory: 'readlink -m %s'\\n" "${_path}"
    fi
    

    # ---------------------------------------------------------------------
    # Check rclone specific info
    # ---------------------------------------------------------------------
    if command -v rclone &> /dev/null
    then
        printf "Using rclone found in PATH:\\n"
        printf "%s\\n" "$(command -v rclone)"
        printf "%s\\n" "$(rclone --version)" 
    else
        printf "rclone could not be found in PATH, so using the MSI module: %s\\n" "/panfs/roc/soft/modulefiles.common/rclone/1.54"
        module load rclone/1.54
        printf "%s\\n" "$(command -v rclone)"
        printf "%s\\n" "$(rclone --version)" 
    fi

    # Make sure the remote exists
    if ! rclone listremotes | grep -q "^$_remote:\$"
    then
        printf "Rclone remote does not exist: %s\\n" "$_remote"
        _exit_1 printf "Check available remotes by running 'rclone listremotes', or set one up by running 'rclone init'.\\n"
    fi

    # Make sure access to bucket is possible
    if ! rclone lsf ${_remote}:${_bucket}
    then
        _exit_1 printf "Errors occured when accessing bucket: '%s'\\nDo you have access rights to the bucket?\\nCheck the bucket access policy using 's3cmd info s3://%s'\\n" "${_bucket}" "${_bucket}"
    fi

    

    # ---------------------------------------------------------------------
    # Check to make sure this input dir does NOT already exist on ceph.
    # ---------------------------------------------------------------------


    # Count the number of ceph objects (files) listed under the input archive dir. If there are any files under this dir name already, stop.
    remote_root_path_dir_filenumber=$(rclone lsf ${_remote}:${_bucket}$(dirname ${_root_path_dir})/$(basename ${_root_path_dir}) --max-depth 1 2> /dev/null | wc -l)


    if [[ $remote_root_path_dir_filenumber -gt 0 ]]
    then
        _exit_1 printf "Tier 2 (ceph) already has files saved under this input 'directory name' (%s) in this bucket (%s). To prevent any possible over-writing of data on ceph, please choose a different panfs directory path to archive or a different ceph bucket.\\n" "${_root_path_dir}" "${_bucket}"
    fi



    # ---------------------------------------------------------------------
    # Create archive working dir
    # ---------------------------------------------------------------------


    _myprefix="panfs2ceph_archive_$(date +"%Y-%m-%d-%H%M%S")"
    _myprefix_dir=$(dirname ${_root_path_dir})/$(basename ${_root_path_dir})___${_myprefix}

    echo ${_myprefix_dir}
    mkdir -p ${_myprefix_dir}
    cd ${_myprefix_dir}






    # ---------------------------------------------------------------------
    # Get a file list
    # ---------------------------------------------------------------------


    if ((_delete_empty_dirs))
    then
        # "The '--delete_empty_dirs' option was specified. Any empty dirs will not be copied to ceph."
        :
    else 
        # Create a hidden file inside all empty dirs. This will ensure the empty dir will get copied as an object to ceph.
        find ${_root_path_dir} -type d -empty -print0 | xargs -I{} -0 touch {}/.empty_dir
    fi



    # Print a list of files that will be archived
    echo "[panfs2ceph "$(date)"] Creating the archive file list. This might take a while for large dirs..."

    rclone lsf -R ${_root_path_dir} > ${_myprefix}.filelist.txt
    # _myprefix the files with full pathname
    sed -i -e "s|^|${_root_path_dir}/|" ${_myprefix}.filelist.txt






    # ---------------------------------------------------------------------
    # Check for filenames or pathnames that are too long
    # ---------------------------------------------------------------------

    # This check is probably pointless because I think the limit is the same for both
    # panfs and ceph -- so if files are on panfs, they should also fit on ceph.

    # On object storage (S3, ceph), filenames are irrelevant. Everything is a filename (with dirs being 
    # represented by slash delimiters). Thus, we only need to test for path length.
    # https://stackoverflow.com/questions/6870824/what-is-the-maximum-length-of-a-filename-in-s3

    pathname_max=1024

    # Are there any with filenames that are too long? They need to be less than 1024 characters (I think?).
    awk '{ PATHNAME=$0; print length(PATHNAME)"\t"PATHNAME}' ${_myprefix}.filelist.txt | awk -v pathname_max=$pathname_max -v out_file="${_myprefix}.filelist.paths_too_long.txt" '{if ($1 >= pathname_max) {print $0 > out_file}}'


    if [[ -s ${_myprefix}.filelist.paths_too_long.txt ]]
    then
        echo "[panfs2ceph "$(date)"] Some pathnames are too long (> $pathname_max char) for ceph. See ${_myprefix}.filelist.paths_too_long.txt for a list. Shorten them before proceeding." >&2
        exit 88
    fi




    #######################################################################
    # Copy
    #######################################################################


    tee ${_myprefix}.1_copy.slurm << EOF > /dev/null
#!/bin/bash
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=1
#SBATCH --cpus-per-task=${_threads}
#SBATCH --time=24:00:00
#SBATCH --mem=32gb
#SBATCH --error=%x.e%j
#SBATCH --output=%x.o%j
#SBATCH --mail-type=BEGIN,END,FAIL
#SBATCH --mail-user=$USER@umn.edu
#SBATCH --partition=amdsmall

echo "[panfs2ceph "\$(date)"] Script start."


# ---------------------------------------------------------------------
# Variables
# ---------------------------------------------------------------------


_root_path_dir=$_root_path_dir
_myprefix=${_myprefix}
_myprefix_dir=${_myprefix_dir}
_dry_run=${_dry_run}
_verbose=${_verbose}
_remote=${_remote}
_bucket=${_bucket}
_threads=${_threads}



# ---------------------------------------------------------------------
# Load software
# ---------------------------------------------------------------------

cd \${_myprefix_dir}

module load rclone/1.54




# ---------------------------------------------------------------------
# rclone
# ---------------------------------------------------------------------



# Copy the files to ceph
rclone copy "/" "\${_remote}:\${_bucket}" --files-from-raw "\${_myprefix}.filelist.txt" \${_dry_run} \${_verbose} --transfers \${_threads} --s3-chunk-size 50M --s3-upload-concurrency 10

if [ ! \$? -eq 0 ]
then
    # rclone exit status was not zero
    echo "[panfs2ceph "\$(date)"] Rclone copy process: FAIL" 2>&1 | tee \${_myprefix}.COPY_FAILED
else
    echo "[panfs2ceph "\$(date)"] Rclone copy process: SUCCESS"
fi




# ---------------------------------------------------------------------
# Verify
# ---------------------------------------------------------------------


# Sleep for a short time to allow rclone to properly list files. If done without
# a short break, rclone lsf seems fail.
echo "[panfs2ceph "\$(date)"] Starting verification..."
#echo "[panfs2ceph "\$(date)"] Waiting for 30 sec to allow ceph to index files..."
#sleep 30
echo "[panfs2ceph "\$(date)"] Getting file list from ceph..."

# Nudge rclone to list the files on bucket (refresh). This seems to help avoid random errors.
#rclone lsf -R \${_remote}: --max-depth 1 > /dev/null
#rclone lsf -R \${_remote}:\${_bucket} --max-depth 1 > /dev/null


# Get a file list from ceph (after the transfer)
rclone lsf -R \${_remote}:\${_bucket}\${_root_path_dir} > \${_myprefix}.filelist_from_ceph.txt

# _myprefix the files with full pathname
sed -i -e "s|^|\${_root_path_dir}/|" \${_myprefix}.filelist_from_ceph.txt




# Compare the sorted files on ceph (just uploaded) against the list of files from panfs
comm -23 <(sort \${_myprefix}.filelist.txt) <(sort \${_myprefix}.filelist_from_ceph.txt) > \${_myprefix}.files_on_panfs_but_not_ceph.txt

comm -13 <(sort \${_myprefix}.filelist.txt) <(sort \${_myprefix}.filelist_from_ceph.txt) > \${_myprefix}.files_on_ceph_but_not_panfs.txt


if [[ ! -s \${_myprefix}.files_on_panfs_but_not_ceph.txt ]]
then
   # The file above is empty.
   #echo "[panfs2ceph "\$(date)"] There are no files in the *.filelist.txt that are missing from ceph."
   rm -rf \${_myprefix}.files_on_panfs_but_not_ceph.txt
else
    echo "[panfs2ceph "\$(date)"] There are files listed in *.filelist.txt that are not found on ceph. Review: \${_myprefix}.files_on_panfs_but_not_ceph.txt" >&2
fi


if [[ ! -s \${_myprefix}.files_on_ceph_but_not_panfs.txt ]]
then
   # The file above is empty.
   #echo "[panfs2ceph "\$(date)"] There are no files on ceph that are not listed in *.filelist.txt."
   rm -rf \${_myprefix}.files_on_ceph_but_not_panfs.txt
else
    echo "[panfs2ceph "\$(date)"] There are files on ceph that are not listed in *.filelist.txt. Review: \${_myprefix}.files_on_ceph_but_not_panfs.txt" >&2
fi







# ---------------------------------------------------------------------
# Job summary info
# ---------------------------------------------------------------------

echo "[panfs2ceph "\$(date)"] Script end."

if [ ! -z \${SLURM_JOB_ID+x} ]; then
    scontrol show job "\${SLURM_JOB_ID}"
    sstat -j "\${SLURM_JOB_ID}" --format=JobID,MaxRSS,MaxVMSize,NTasks,MaxDiskWrite,MaxDiskRead
fi







EOF







    #######################################################################
    # Delete
    #######################################################################


    tee ${_myprefix}.2_delete.slurm << EOF > /dev/null
#!/bin/bash
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=1
#SBATCH --cpus-per-task=1
#SBATCH --time=24:00:00
#SBATCH --mem=32gb
#SBATCH --error=%x.e%j
#SBATCH --output=%x.o%j
#SBATCH --mail-type=BEGIN,END,FAIL
#SBATCH --mail-user=$USER@umn.edu
#SBATCH --partition=amdsmall

echo "[panfs2ceph "\$(date)"] Script start."


# ---------------------------------------------------------------------
# Variables
# ---------------------------------------------------------------------


_root_path_dir=${_root_path_dir}
_myprefix=${_myprefix}
_myprefix_dir=${_myprefix_dir}
_dry_run=${_dry_run}
_verbose=${_verbose}



# ---------------------------------------------------------------------
# Software
# ---------------------------------------------------------------------

cd \${_myprefix_dir}

module load /home/lmnp/knut0297/software/modulesfiles/rsync/3.1.2


# ---------------------------------------------------------------------
# Delete files from panfs
# ---------------------------------------------------------------------

# Delete all files in the file list
# Use rsync to delte files because it's faster than "rm"

_empty_dir=\${_myprefix_dir}/empty_dir

mkdir -p \${_empty_dir}

rsync \${_dry_run} \${_verbose} -a --force --delete \${_empty_dir}/ \${_root_path_dir}/



if [ ! \$? -eq 0 ]
then
    # rclone exit status was not zero
    echo "[panfs2ceph "\$(date)"] Delete process: FAIL" 2>&1 | tee \${_myprefix}.DELETE_FAILED
else
    echo "[panfs2ceph "\$(date)"] Delete process: SUCCESS"
fi

# Delete the original archive dir and the temp empty dir
rm -rf \${_root_path_dir}
rm -rf \${_empty_dir}





# ---------------------------------------------------------------------
# Job summary info
# ---------------------------------------------------------------------

echo "[panfs2ceph "\$(date)"] Script end."

if [ ! -z \${SLURM_JOB_ID+x} ]; then
    scontrol show job "\${SLURM_JOB_ID}"
    sstat -j "\${SLURM_JOB_ID}" --format=JobID,MaxRSS,MaxVMSize,NTasks,MaxDiskWrite,MaxDiskRead
fi



EOF







    #######################################################################
    # Restore
    #######################################################################


    tee ${_myprefix}.3_restore.slurm << EOF > /dev/null
#!/bin/bash
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=1
#SBATCH --cpus-per-task=${_threads}
#SBATCH --time=24:00:00
#SBATCH --mem=32gb
#SBATCH --error=%x.e%j
#SBATCH --output=%x.o%j
#SBATCH --mail-type=BEGIN,END,FAIL
#SBATCH --mail-user=$USER@umn.edu
#SBATCH --partition=amdsmall

echo "[panfs2ceph "\$(date)"] Script start."


# ---------------------------------------------------------------------
# Variables
# ---------------------------------------------------------------------


_root_path_dir=${_root_path_dir}
_myprefix=${_myprefix}
_myprefix_dir=${_myprefix_dir}
_dry_run=${_dry_run}
_verbose=${_verbose}
_remote=${_remote}
_bucket=${_bucket}
_threads=${_threads}



# ---------------------------------------------------------------------
# Load software
# ---------------------------------------------------------------------



module load rclone/1.54



# ---------------------------------------------------------------------
# Check if original dir still exists on panfs
# ---------------------------------------------------------------------

if [ -d "\${_root_path_dir}" ]
then
    echo "[panfs2ceph "\$(date)"] The original dir (\${_root_path_dir}) still exists on panfs. Stopping restore process. Change the dir name on panfs and re-run restore script." >&2
    exit 1
fi



# ---------------------------------------------------------------------
# rclone
# ---------------------------------------------------------------------

# Nudge rclone to list the files on bucket (refresh). This seems to help avoid random errors.
rclone lsf -R \${_remote}:\${_bucket} --max-depth 1 > /dev/null


# Copy the files from ceph back to panfs
rclone copy "\${_remote}:\${_bucket}\${_root_path_dir}" "\${_root_path_dir}" \${_dry_run} \${_verbose} --transfers \${_threads} --s3-chunk-size 50M --s3-upload-concurrency 10


if [ ! \$? -eq 0 ]
then
    # rclone exit status was not zero
    echo "[panfs2ceph "\$(date)"] rclone restore process: FAIL" 2>&1 | tee \${_myprefix}.RESTORE_FAILED
else
    echo "[panfs2ceph "\$(date)"] rclone restore process: SUCCESS"
fi



# ---------------------------------------------------------------------
# Job summary info
# ---------------------------------------------------------------------

echo "[panfs2ceph "\$(date)"] Script end."

if [ ! -z \${SLURM_JOB_ID+x} ]; then
    scontrol show job "\${SLURM_JOB_ID}"
    sstat -j "\${SLURM_JOB_ID}" --format=JobID,MaxRSS,MaxVMSize,NTasks,MaxDiskWrite,MaxDiskRead
fi







EOF






    #######################################################################
    # Readme
    #######################################################################



    tee ${_myprefix}.readme.md << EOF > /dev/null


# panfs2ceph archive

## Introduction

This directory (\`${_root_path_dir}\`) was archived from MSI's \`panfs\` (tier 1) storage to its \`ceph\` tier 2 storge. All data inside the directory was copied using \`rclone\` which uses MD5 checksums on every transfer to ensure data integrity. After the data was copied, it was deleted from \`panfs\`. 


## How this works

* A program called \`panfs2ceph\` found all the files in a directory to archive and created a file list text file.
* Then the program created a slurm job file (bash script) that can be run to copy all files from panfs to ceph.
* The program also created a slurm job file (bash script) to delete the original data from panfs.
* The program also created this README file.
* The program does not actually run these slrum job scripts. You must do that manually after reviewing the file list, etc.


## Notes:

* A new dir is created next to the original that contains these archive-related files and scripts.



## Variables


Variable Name | Value 
-----------|----------
Directory to archive | ${_root_path_dir}
Directory name for archive files | ${_myprefix}
Directory path for archive files | ${_myprefix_dir}
Ceph UserID | $(s3info info | grep username | awk -F': ' '{print $2}')
Ceph Remote Name | ${_remote}
Ceph Bucket Name | ${_bucket}
User doing transfer | $USER


## How to access the original data

### Browse the data on ceph

You can use a variety of tools to browse data stored on ceph. For example:

1. rclone (e.g. \`rclone ls ${_remote}:${_bucket}${_root_path_dir}\`). This requires a properly configured \`~/.config/rclone/rclone.conf\` file. 
2. s3cmd (e.g. \`s3cmd ls -r s3://${_bucket}${_root_path_dir}\`). This requires a properly configured \`~/.s3cfg\` file. 
3. GUI based file browser (e.g. FileZilla, Panic's Transmit, CyberDuck, etc.)


### Browse the data via panfs \`snapshot\`

The original data was deleted, but might still be stored on \`panfs\` as a snapshot for a short period of time (approximately 1 month or less). If this data was archived to ceph and deleted from panfs, it might be recovered from panfs for a short time. Review the available snapshots here:

    ${_root_path_dir}/.snapshot


### Restore from ceph back to panfs

Depending on user permissions, the data can be copied from ceph back to panfs using \`rclone\` or other methods. For example, running ${_myprefix}.3_restore.slurm job script should copy the data from ceph back to panfs in its original location.





EOF




    #######################################################################
    # Print instructions to terminal
    #######################################################################

    echo "[panfs2ceph "$(date)"] Done."


    #read -r -d '' instructions_message << EOF > /dev/null

    # The unix "read" command does not return a zero exit code. Use a temp function instead.
    # https://stackoverflow.com/a/8088167/2367748
    heredoc2var(){ IFS='\n' read -r -d '' ${1} || true; }
    
    heredoc2var instructions_message << EOF > /dev/null

---------------------------------------------------------------------
cephtools panfs2ceph summary

Options used:
dry_run=${_dry_run}
verbose=${_verbose}
delete_empty_dirs=${_delete_empty_dirs}
remote=${_remote}
bucket=${_bucket}
threads=${_threads}

Archive dir: 
${_root_path_dir}

Archive dir transfer scripts:
${_myprefix_dir}

Achrive transfer files created -- but you're not done yet!
Next steps:
1. Move into transfer dir: cd ${_myprefix_dir}
2. Review the *.readme.md file for details.
3. Review the *.filelist.txt file. The files in this list will be copied to ceph and delted from panfs.
4. Launch the copy jobfile: sbatch ${_myprefix}.1_copy.slurm
5. After sucessful copy, launch the delete jobfile: sbatch ${_myprefix}.2_delete.slurm
6. After the data has been deleted from panfs -- and you need it back in the same location, launch the restore jobfile: sbatch ${_myprefix}.3_restore.slurm

VERSION: ${_VERSION}
QUESTIONS: Todd Knutson (knut0297@umn.edu)
REPO: https://github.umn.edu/knut0297org/cephtools
---------------------------------------------------------------------
EOF


    echo "$instructions_message"


}






###############################################################################
# Run Program
###############################################################################

# Call the `_main` function after everything has been defined.
_main
