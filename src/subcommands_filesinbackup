


# ---------------------------------------------------------------------
# filesinbackup
# ---------------------------------------------------------------------

describe "filesinbackup" <<HEREDOC
---------------------------------------------------------------------
Usage:
    ${_ME} filesinbackup [options] --bucket <BUCKET> --group <GROUP>

Options:                            
    -b|--bucket <STRING>    Name of the ceph bucket that data should be used for the 
                            transfer. [Default = "data-delivery-$(id -ng)"]
    
    -g|--group <STRING>     MSI group id. [Default = "$(id -ng)"]

    -l|--log_dir <STRING>   Absolute or relative path to the directory where log files
                            are saved. [Default = "/home/$(id -ng)/shared/cephtools/filesinbackup"]
    
    -v|--verbose            Verbose mode (print additional info).
                            
    -t|--threads <INT>      Threads to use for uploading with rclone. [Default = 16].
    

Description:
  Print list of files in a group's disater_recovery folder and a list of files in a bucket on Tier 2 
  and emails those lists to the group PI. 
  
Help (print this screen):
    ${_ME} help filesinbackup

Version: ${VERSION_SHORT}
Questions: Todd Knutson (knut0297@umn.edu) or Christine O'Connor (oconnorc@umn.edu)
GitHub: https://github.umn.edu/lmnp/cephtools
---------------------------------------------------------------------
HEREDOC


filesinbackup() {
#     echo ALL ARGS:
#     echo "${@:-}"
#     echo "${#}"


    
    # Parse Options ###############################################################

    # Initialize program option variables.
    local _bucket="data-delivery-$(id -ng)"
    local _disaster_recovery_path="/home/$(id -ng)/shared/disaster_recovery"
    local _log_dir="/home/$(id -ng)/shared/cephtools/filesinbackup"
    local _group="$(id -ng)
    local _verbose=
    local _threads="8"

    # __get_option_value()
    #
    # Usage:
    #   __get_option_value <option> <value>
    #
    # Description:
    #  Given a flag (e.g., -e | --example) return the value or exit 1 if value
    #  is blank or appears to be another option.
    __get_option_value() {
      local __arg="${1:-}"
      local __val="${2:-}"
      
      if [[ -n "${__val:-}" ]] && [[ ! "${__val:-}" =~ ^- ]]
      then
        printf "%s\\n" "${__val}"
      else
        _exit_1 printf "%s requires a valid argument.\\n" "${__arg}"
      fi
    }


    # For flags (i.e. no corresponding value), do not shift inside the case testing
    # statement. For options with required value, shift inside case testing statement, 
    # so the loop moves twice. 
    while ((${#}))
    do
        __arg="${1:-}"
        __val="${2:-}"

        case "${__arg}" in
        -v|--verbose)
            _verbose=1
            ;;
        -b|--bucket)
            _bucket="$(__get_option_value "${__arg}" "${__val:-}")"
            shift
            ;;
        -g|--group)
            _group="$(__get_option_value "${__arg}" "${__val:-}")"
            shift
            ;;
        -l|--log_dir)
            _log_dir="$(__get_option_value "${__arg}" "${__val:-}")"
            shift
            ;;
        -t|--threads)
            _threads="$(__get_option_value "${__arg}" "${__val:-}")"
            shift
            ;;
        --endopts)
            # Terminate option parsing.
            break
            ;;
        -*)
            _exit_1 printf "Unexpected option: %s\\n" "${__arg}"
            ;;
        *)
            describe --get filesinbackup
            _exit_1 printf "Unexpected positional arg: %s\\n" "${__arg}"
            ;;
        esac

        shift
    done


    # ---------------------------------------------------------------------
    # Check and print input options
    # ---------------------------------------------------------------------

    _verb printf -- "Program options used:\\n"
    _verb printf -- "--bucket: %s\\n" "$_bucket"
    _verb printf -- "--group: %s\\n" "$_group"
    _verb printf -- "--log_dir: %s\\n" "$_log_dir"
    _verb printf -- "--verbose: %s\\n" "$_verbose"
    _verb printf -- "--threads: %s\\n" "$_threads"


    
    # If required options are empty or null, exit.
    #if [ -z "${_remote}" ]
    #then
    #    _exit_1 printf "The '--remote' option must be specified and not be empty or null."
    #fi
    

    _root_path_dir=$(readlink -m "${_path}")
    if [ ! -d "${_root_path_dir}" ]
    then
        _exit_1 printf "The '--path' option specified is not a valid directory. \\nReadlink does not convert to a valid directory: 'readlink -m %s'\\n" "${_path}"
    fi


    if command -v rclone &>/dev/null
    then
        RCLONE_MINOR_VER="$(rclone --version | head -n 1 | sed 's/rclone v..//' | sed 's/\..*$//')"
        if [ "$RCLONE_MINOR_VER" -ge "57" ]
        then
            _verb printf "Using rclone found in PATH:\\n"
            _verb printf "%s\\n" "$(command -v rclone)"
            _verb printf "%s\\n" "$(rclone --version)"
        else
            _warn printf "rclone in your PATH was a version less than 1.57, so using the module: %s\\n" "/home/lmnp/knut0297/software/modulesfiles/rclone/1.57.0"
            MODULEPATH="/home/lmnp/knut0297/software/modulesfiles" module load rclone/1.57.0
            _verb printf "%s\\n" "$(command -v rclone)"
            _verb printf "%s\\n" "$(rclone --version)" 
        fi
    else
        _warn printf "rclone could not be found in PATH, so using the module: %s\\n" "/home/lmnp/knut0297/software/modulesfiles/rclone/1.57.0"
        MODULEPATH="/home/lmnp/knut0297/software/modulesfiles" module load rclone/1.57.0
        _verb printf "%s\\n" "$(command -v rclone)"
        _verb printf "%s\\n" "$(rclone --version)" 
    fi


    if [ ! -d "${_log_dir}" ]
    then
        _warn printf "The '--log_dir' option specified is not a valid directory. Creating the dir with g+rwx permissions: '%s'\\n" "${_log_dir}"
        mkdir -p ${_log_dir}
        chmod g+rwx ${_log_dir}
    fi

    # Make sure the remote exists
#    if ! rclone listremotes | grep -q "^$_remote:\$"
#    then
#        _exit_1 printf "Rclone remote does not exist: %s\\nCheck available remotes by running 'rclone listremotes', or set one up by running 'rclone init'.\\n" "$_remote"
#    fi

     # ---------------------------------------------------------------------
     # Set the environment
     # ---------------------------------------------------------------------
     # set the environment here as well so I can check bucket access
     export RCLONE_CONFIG_MYREMOTE_TYPE=s3


     export RCLONE_CONFIG_MYREMOTE_ENV_AUTH=FALSE
     export RCLONE_CONFIG_MYREMOTE_ACCESS_KEY_ID=$(s3info --keys | awk '{print $1}')
     export RCLONE_CONFIG_MYREMOTE_SECRET_ACCESS_KEY=$(s3info --keys | awk '{print $2}')
     export RCLONE_CONFIG_MYREMOTE_ENDPOINT=s3.msi.umn.edu
     export RCLONE_CONFIG_MYREMOTE_ACL=private
     export RCLONE_CONFIG_MYREMOTE_PROVIDER=Ceph

       #rclone lsd MYREMOTE:

    # Make sure access to bucket is possible
    if ! rclone lsf MYREMOTE:${_bucket} &>/dev/null
    then
        _exit_1 printf "Errors occured when accessing bucket: '%s'\\nDoes the bucket exist?\\nDo you have access rights to the bucket?\\nCheck the bucket access policy using 's3cmd info s3://%s'\\nOr the MSI group PI should create the bucket using 's3cmd mb s3://%s'\\n" "${_bucket}" "${_bucket}" "${_bucket}"
    fi

    # ---------------------------------------------------------------------
    # Check s3cmd specific info
    # ---------------------------------------------------------------------

    # Only need to check that we can access s3cmd commands
    S3CMD="$(which s3cmd)"
    if command -v s3cmd &> /dev/null
    then
        _verb printf "Using s3cmd found in PATH: %s\\n" "$(which s3cmd)"
        _verb printf "%s\\n" "$(s3cmd --version)" 
    else
        _exit_1 printf "s3cmd could not be found in PATH\\n"
    fi
    


    # ---------------------------------------------------------------------
    # Create archive working dir
    # ---------------------------------------------------------------------

    _archive_date_time="$(date +"%Y-%m-%d-%H%M%S")"
    _myprefix="filesinbackup_${_archive_date_time}"
    _myprefix_dir=${_log_dir}/${_myprefix}

    _verb printf "Archive dir name: %s\\n" ${_myprefix_dir}
    mkdir -p ${_myprefix_dir}
    chmod g+rwx ${_myprefix_dir}
    cd ${_myprefix_dir}





    # ---------------------------------------------------------------------
    # Determine best slurm partition
    # ---------------------------------------------------------------------

    # Capture the dns domain name for current cluster
    cluster=$(dnsdomainname | awk -F. '{print $1}')

    # Specify the appropriate slurm partition in job files
    if [[ "${cluster}" = "agate" ]]; then
        _partition="msismall"
    elif [[ "${cluster}" = "mesabi" ]]; then
        _partition="msismall"
    elif [[ "${cluster}" = "mangi" ]]; then
        _partition="msismall"
    else
        _partition="msismall"
    fi




    #######################################################################
    # Copy
    #######################################################################


    tee ${_myprefix}.list.slurm << EOF > /dev/null
#!/bin/bash
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=1
#SBATCH --cpus-per-task=${_threads}
#SBATCH --time=2:00:00
#SBATCH --mem=2gb
#SBATCH --error=%x.e%j
#SBATCH --output=%x.o%j
#SBATCH --mail-type=BEGIN,END,FAIL
#SBATCH --mail-user=$USER@umn.edu
#SBATCH --partition=$_partition

echo "[filesinbackup "\$(date)"] Script start."


# ---------------------------------------------------------------------
# Variables
# ---------------------------------------------------------------------


_myprefix=${_myprefix}
_myprefix_dir=${_myprefix_dir}
_bucket=${_bucket}
_threads=${_threads}
_disaster_recovery_path=${_disaster_recovery_path}
_archive_date_time=${_archive_date_time}

# ---------------------------------------------------------------------
# Load software
# ---------------------------------------------------------------------

cd \${_myprefix_dir}

MODULEPATH="/home/lmnp/knut0297/software/modulesfiles" module load rclone/1.57.0


# ---------------------------------------------------------------------
# Set the environment
# ---------------------------------------------------------------------

export RCLONE_CONFIG_MYREMOTE_TYPE=s3


export RCLONE_CONFIG_MYREMOTE_ENV_AUTH=FALSE
export RCLONE_CONFIG_MYREMOTE_ACCESS_KEY_ID=$(s3info --keys | awk '{print $1}')
export RCLONE_CONFIG_MYREMOTE_SECRET_ACCESS_KEY=$(s3info --keys | awk '{print $2}')
export RCLONE_CONFIG_MYREMOTE_ENDPOINT=s3.msi.umn.edu
export RCLONE_CONFIG_MYREMOTE_ACL=private
export RCLONE_CONFIG_MYREMOTE_PROVIDER=Ceph

rclone lsd MYREMOTE:



# ---------------------------------------------------------------------
# List files in back up directories
# ---------------------------------------------------------------------

_attachement_1=\${_myprefix}.filelist_from_ceph.txt
_attachement_2=\${_myprefix}.filelist_from_dr.txt
# files on ceph/Tier2
echo "[filesinbackup "\$(date)"] Getting file list from ceph..."
#rclone lsf -R --copy-links MYREMOTE:\${_bucket}\${_root_path_dir} > \${_attachement_1}
s3cmd ls --recursuve s3://${_bucket}  > \${_attachement_1}
## need to use s3cmd to get all files in Tier2 bucket that 

# files in disaster_recovery
rclone lsf -R --copy-links \${_disaster_recovery_path} > \${_attachement_2}



# ---------------------------------------------------------------------
# Send email 
# ---------------------------------------------------------------------


EMAIL_SUBJECT="Your group's disaster_recovery and tier2 files: ${_archive_date_time}"
EMAIL_NAME=$USER
EMAIL_TO=$USER@umn.edu
EMAIL_REPLY=$USER@umn.edu

EMAIL_BODY="Hi ${EMAIL_NAME},

Here are lists of files in disaster recovery and in \${_bucket}

Goodbye!
"




# Send the email by piping a HEREDOC to the sendmail command
sendmail -t << HEREDOC
Subject: ${EMAIL_SUBJECT}
To: ${EMAIL_TO}
Cc: ${EMAIL_TO}
Reply-To: ${EMAIL_REPLY}
MIME-Version: 1.0
Content-Type: multipart/mixed; boundary=XYZ

--XYZ
Content-Type: text/plain

${EMAIL_BODY}

--XYZ
Content-Type: text/plain; name="${_attachement_1}"
Content-Disposition: attachment; filename="${_attachement_1}"

$(cat ${ATTACHMENT_1})

--XYZ
Content-Type: text/plain; name="${_attachement_2}"
Content-Disposition: attachment; filename="${_attachement_2}"

$(cat ${ATTACHMENT_2})

--XYZ--
HEREDOC

# ---------------------------------------------------------------------
# Job summary info
# ---------------------------------------------------------------------

echo "[filesinbackup "\$(date)"] Script end."

if [ ! -z \${SLURM_JOB_ID+x} ]; then
    scontrol show job "\${SLURM_JOB_ID}"
    sstat -j "\${SLURM_JOB_ID}" --format=JobID,MaxRSS,MaxVMSize,NTasks,MaxDiskWrite,MaxDiskRead
fi







EOF


# ---------------------------------------------------------------------
# Launch jobs
# ---------------------------------------------------------------------


# no dry run option here

sbatch_output=$(sbatch "${_myprefix}.list.slurm")
job_id=$(echo "${sbatch_output}" | awk '{print $4}')
sbatch_job_ids+=("${job_id}")
_verb printf "%s\n" "${sbatch_output}"
_info printf "\${_myprefix}.list.slurm job file created and launched.\n"



