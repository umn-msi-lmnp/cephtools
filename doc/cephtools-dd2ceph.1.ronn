# cephtools-dd2ceph(1) - archive the data_delivery directory on panfs to ceph


## SYNOPSIS

`cephtools dd2ceph [--subcommand-options]`

## DESCRIPTION

`cephtools dd2ceph` is a bash script that facilitates transferring data from `/home/GROUP/data_delivery` on *panfs* to *ceph*. It has only a few options and is fairly strict in functionality. Its sole purpose is to copy a single directory from tier 1 (*panfs*) storage to tier 2 (*ceph*). 


### Files generated

The script does not actually transfer any data. It simply examines a single input dir on *panfs* and creates three files: 

1. file list (relative file names converted to absolute path names)
2. slurm jobscript (copy data from *panfs* to *ceph*)
5. a detailed readme file. 

The slurm jobscript must be launched manually. This allows for time to review the readme, script, and file list.





### Details

* All data is copied using `rclone`, which uses MD5 checksums and auto retries on every file transfer to ensure data integrity. 
* The data is not compressed or tar archived (e.g. *.tar.gz*) before transfer. This is intentional. If all files from a large project (i.e. > 1 TB) were concatenated with `tar`, a small data corruption in this huge single file could make recovery of any underlying files difficult. Instead, individual files should be compressed on *panfs* prior to transfer to *ceph*. 
* Uploading individual files allows for easier data browsing directly on *ceph* and/or restoring individual files.
* Each file is transferred to *ceph* as an absolute path name. This creates a lot of "pseudo" dirs on *ceph*, but it helps indicate where the data originally came from on *panfs*
* You must have a properly configured `rclone` installation running on *panfs*. For help setting up `rclone`, see: [https://github.umn.edu/lmnp/tips/tree/master/rclone](https://github.umn.edu/lmnp/tips/tree/master/rclone)
* Setting the `--threads` option will create slurm jobscripts using this thread count. `rclone` can transfer data in a multi-threaded way. So this can dramatically increase your overall transfer speed.
* If a bucket does not already exist on *ceph*, it will get created automatically.
* After the data is transferred to *ceph*, the files are verified. Files on *ceph* are listed by rclone and compared against the original input file list. If differences occur, an error will occur. This process occurs at the end of the "copy" jobscript.




## EXAMPLES

```
cephtools dd2ceph --remote ceph --bucket $(id -ng)-data-archive --path /home/$(id -ng)/data_delivery
```


### Demo


## SEE ALSO

The various subcommands can be found by running: `cephtools subcommands`

## BUGS

See the *Issues* section on GitHub: [https://github.umn.edu/lmnp/cephtools](https://github.umn.edu/lmnp/cephtools)
    
## AUTHOR

Todd P. Knutson [knut0297@umn.edu](mailto:knut0297@umn.edu). See GitHub for other contributors.
   
## COPYRIGHT

Copyright Â© 2021 University of Minnesota. License MIT.



